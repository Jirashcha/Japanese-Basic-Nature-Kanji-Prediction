{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jirashcha/Japanese-Basic-Nature-Kanji-Prediction/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aeq5Lo04NnNU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,BatchNormalization\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HM1fn_LwNnNV"
      },
      "outputs": [],
      "source": [
        "#first we will load dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN4Psz4wOpuI",
        "outputId": "536f2062-a908-4ba8-be1a-3a503338ecc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def load_and_resize_images_from_folder(folder, target_size=(28, 28)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for subfolder in os.listdir(folder):\n",
        "        subfolder_path = os.path.join(folder, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            for filename in os.listdir(subfolder_path):\n",
        "                img_path = os.path.join(subfolder_path, filename)\n",
        "                if img_path.endswith(\".jpg\") or img_path.endswith(\".png\"):\n",
        "                    # Load image in grayscale\n",
        "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is not None:\n",
        "                        # Resize the image\n",
        "                        img_resized = cv2.resize(img, target_size)\n",
        "                        images.append(img_resized)\n",
        "                        labels.append(subfolder)  # Use subfolder name as label\n",
        "    return images, labels\n",
        "\n",
        "# Assuming you have a folder with subfolders containing images\n",
        "folder_path = \"/content/drive/MyDrive/kanji\"\n",
        "images, labels = load_and_resize_images_from_folder(folder_path)\n",
        "\n",
        "# Convert labels to integers using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "# Adjust the test_size according to your preference\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "# Normalize pixel values to range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "num_classes = len(np.unique(labels_encoded))\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# Now you have x_train, x_test, y_train, and y_test ready to be used for training your AI model\n"
      ],
      "metadata": {
        "id": "q5xWrt5wOJlg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UD18XMYNnNV",
        "outputId": "4bc2a007-3d79-4226-a379-4bfdf1859d75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# (x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyRhFVT0NnNW",
        "outputId": "2d97b038-8bc3-4df3-8ee2-d50359091a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of x_train (32, 28, 28)\n",
            "Dimension of x_test (8, 28, 28)\n",
            "Dimension of y_test (8, 4)\n"
          ]
        }
      ],
      "source": [
        "#Now we will se our dataset\n",
        "\n",
        "print(\"Dimension of x_train\",x_train.shape)\n",
        "print(\"Dimension of x_test\",x_test.shape)\n",
        "print(\"Dimension of y_test\",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "rDL7r7mANnNW",
        "outputId": "f1ea35fc-f76d-484f-daf3-17c08a1d5f92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "#we will see a single image in out dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[4])\n",
        "plt.show()\n",
        "print(y_train[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nK8DMQykNnNW"
      },
      "outputs": [],
      "source": [
        "#Now defining some parameters for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "qghBJvSaNnNW"
      },
      "outputs": [],
      "source": [
        "num_classes = 4\n",
        "#as we have 10 classes (0-9)\n",
        "#we need to prdeict one out of 10 which has high probability\n",
        "epochs = 30\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "#as each image is 28 by 28 pixel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "7m2VACt_NnNX"
      },
      "outputs": [],
      "source": [
        "#build our model\n",
        "#BY DEFAULT STRIDE IS 1\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28,28,1)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "J4DLRagiNnNX"
      },
      "outputs": [],
      "source": [
        "#compile our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "R8GVRqOaNnNX"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXLt1zaGNnNX",
        "outputId": "afd4ad4b-8181-4153-9285-5e4a4f52abcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_19 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 11, 11, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 11, 11, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 6, 6, 32)          25632     \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 6, 6, 32)          128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 4, 4, 64)          18496     \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 4, 4, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 2, 2, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 2, 2, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 1, 1, 64)          102464    \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 1, 1, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 1, 1, 64)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 194372 (759.27 KB)\n",
            "Trainable params: 193860 (757.27 KB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnW_5Z0kNnNX",
        "outputId": "fd594ff4-f891-4e60-bca0-5454450e63ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.1177 - accuracy: 0.9688 - val_loss: 1.4360 - val_accuracy: 0.2500\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 1.4379 - val_accuracy: 0.2500\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1029 - accuracy: 0.9375 - val_loss: 1.4404 - val_accuracy: 0.2500\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.1111 - accuracy: 0.9375 - val_loss: 1.4427 - val_accuracy: 0.2500\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0913 - accuracy: 0.9688 - val_loss: 1.4447 - val_accuracy: 0.2500\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 1.4470 - val_accuracy: 0.2500\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0734 - accuracy: 0.9688 - val_loss: 1.4484 - val_accuracy: 0.1250\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.4496 - val_accuracy: 0.2500\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 1.4519 - val_accuracy: 0.2500\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 1.4544 - val_accuracy: 0.2500\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 1.4572 - val_accuracy: 0.1250\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.4597 - val_accuracy: 0.1250\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.4630 - val_accuracy: 0.1250\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0713 - accuracy: 0.9688 - val_loss: 1.4663 - val_accuracy: 0.1250\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 1.4702 - val_accuracy: 0.1250\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 1.4733 - val_accuracy: 0.1250\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.4767 - val_accuracy: 0.1250\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.4795 - val_accuracy: 0.1250\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0596 - accuracy: 0.9688 - val_loss: 1.4831 - val_accuracy: 0.1250\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0747 - accuracy: 0.9688 - val_loss: 1.4874 - val_accuracy: 0.1250\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.4919 - val_accuracy: 0.1250\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.4965 - val_accuracy: 0.1250\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0793 - accuracy: 0.9688 - val_loss: 1.5013 - val_accuracy: 0.1250\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.5061 - val_accuracy: 0.1250\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 1.5116 - val_accuracy: 0.1250\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5171 - val_accuracy: 0.1250\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.5223 - val_accuracy: 0.1250\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.5277 - val_accuracy: 0.1250\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0622 - accuracy: 0.9688 - val_loss: 1.5327 - val_accuracy: 0.1250\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.5373 - val_accuracy: 0.1250\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.5421 - val_accuracy: 0.1250\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.5470 - val_accuracy: 0.1250\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.5522 - val_accuracy: 0.1250\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.5565 - val_accuracy: 0.1250\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.5614 - val_accuracy: 0.1250\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.1250\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 1.5722 - val_accuracy: 0.1250\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.5778 - val_accuracy: 0.1250\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.5830 - val_accuracy: 0.1250\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.5884 - val_accuracy: 0.1250\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.5937 - val_accuracy: 0.1250\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5991 - val_accuracy: 0.1250\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 1.6049 - val_accuracy: 0.1250\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0449 - accuracy: 0.9688 - val_loss: 1.6094 - val_accuracy: 0.1250\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.6143 - val_accuracy: 0.1250\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.6187 - val_accuracy: 0.2500\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 1.6232 - val_accuracy: 0.2500\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.6288 - val_accuracy: 0.2500\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.6342 - val_accuracy: 0.2500\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.6392 - val_accuracy: 0.2500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7da9e5f23940>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "#fit the model\n",
        "model.fit(x_train,y_train,batch_size=32,epochs=50,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOS3L9V-NnNX",
        "outputId": "450fade1-3077-4e85-c694-0afb06d5b651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6392 - accuracy: 0.2500\n",
            "Score is : 1.6392161846160889\n",
            "Accuracy : 0.25\n"
          ]
        }
      ],
      "source": [
        "score ,acc = model.evaluate(x_test,y_test)\n",
        "print(\"Score is :\",score)\n",
        "print(\"Accuracy :\",acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsB4TZFxNnNY"
      },
      "outputs": [],
      "source": [
        "#save our model\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\",\"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"models.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoIUZsqeNnNY"
      },
      "outputs": [],
      "source": [
        "import tensorflowjs as tfjs\n",
        "tfjs.converters.save_keras_model(model,'/home/ubuntu/love/keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVG0DiclNnNY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}